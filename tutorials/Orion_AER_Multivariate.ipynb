{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Orion on Multivariate Input\n",
    "\n",
    "In this notebook, we demonstrate how you can use multivariate time series in Orion. We will walk through the process using NASA's dataset, you can find the original data in [Telemanom](https://github.com/khundman/telemanom) github or directly from their [S3 bucket](https://s3-us-west-2.amazonaws.com/telemanom/data.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "In the first step, we setup the environment and load the CSV that we want to process.\n",
    "\n",
    "To do so, we need to import the `orion.data.load_signal` function and call it passing\n",
    "the path to the CSV file.\n",
    "\n",
    "In this case, we will be loading the `S-1.csv` file from inside the `data/multivariate` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1    v2     v3   v4   v5   v6     v7     v8     v9    v10    v11  \\\n",
      "0 -2.00  1.51  10.14  0.0  0.0  0.0 -15.78 -22.31 -11.70 -13.57  92.95   \n",
      "1 -2.00  1.51  10.13  0.0  0.0  0.0 -16.86 -23.38 -10.31 -13.57  92.95   \n",
      "2 -2.00  1.51  10.13  0.0  0.0  0.0 -16.86 -23.38 -10.31 -13.57  92.95   \n",
      "3 -1.99  1.51  10.17  0.0  0.0  0.0 -16.86 -23.38 -10.31 -13.57  92.95   \n",
      "4 -1.99  1.51  10.17  0.0  0.0  0.0 -16.86 -23.38 -10.31 -13.57  92.95   \n",
      "\n",
      "            timestamp  \n",
      "0 2024-01-01 00:00:00  \n",
      "1 2024-01-01 00:00:01  \n",
      "2 2024-01-01 00:00:02  \n",
      "3 2024-01-01 00:00:03  \n",
      "4 2024-01-01 00:00:04  \n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "reference_time = pd.Timestamp('2024-01-01 00:00:00')\n",
    "data = pd.read_csv(\"/Users/coloner/IdeaProjects/ml/Orion/data/TimeSeries.csv\")\n",
    "\n",
    "data['timestamp'] = pd.to_datetime(data.index, unit='s', origin=reference_time)\n",
    "\n",
    "\n",
    "print(data.head())\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = data['timestamp'].view('int64') \n",
    "data['timestamp'] /= 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = data['timestamp'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509632, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detect anomalies using Orion\n",
    "\n",
    "Once we have the data, let us try to use the LSTM pipeline to analyze it and search for anomalies.\n",
    "\n",
    "In order to do so, we will import the `Orion` class from `orion.core` and pass it\n",
    "the loaded data and the path to the pipeline JSON that we want to use.\n",
    "\n",
    "In this case, we will be using the `lstm_dynamic_threshold` pipeline from inside the `orion` folder. \n",
    "\n",
    "In addition, we setup the hyperparameters to correctly identify the signal we are trying to predict. In this case, dimension `0` is the signal value and such we set `target_column` to `0`. Note that `0` refers to the location of the channel rather than the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6370/6370 [==============================] - 659s 100ms/step - loss: 4.2088e-04 - tf.__operators__.getitem_3_loss: 3.6904e-04 - tf.__operators__.getitem_4_loss: 4.7876e-04 - tf.__operators__.getitem_5_loss: 3.5695e-04 - val_loss: 0.0018 - val_tf.__operators__.getitem_3_loss: 0.0016 - val_tf.__operators__.getitem_4_loss: 0.0017 - val_tf.__operators__.getitem_5_loss: 0.0020\n",
      "Epoch 2/5\n",
      "6370/6370 [==============================] - 19400s 3s/step - loss: 3.2820e-04 - tf.__operators__.getitem_3_loss: 2.6621e-04 - tf.__operators__.getitem_4_loss: 3.8614e-04 - tf.__operators__.getitem_5_loss: 2.7433e-04 - val_loss: 0.0016 - val_tf.__operators__.getitem_3_loss: 0.0016 - val_tf.__operators__.getitem_4_loss: 0.0015 - val_tf.__operators__.getitem_5_loss: 0.0019\n",
      "Epoch 3/5\n",
      "6370/6370 [==============================] - 16732s 3s/step - loss: 2.8668e-04 - tf.__operators__.getitem_3_loss: 2.4305e-04 - tf.__operators__.getitem_4_loss: 3.2776e-04 - tf.__operators__.getitem_5_loss: 2.4815e-04 - val_loss: 0.0022 - val_tf.__operators__.getitem_3_loss: 0.0023 - val_tf.__operators__.getitem_4_loss: 0.0023 - val_tf.__operators__.getitem_5_loss: 0.0020\n",
      "Epoch 4/5\n",
      "6370/6370 [==============================] - 234s 37ms/step - loss: 2.5682e-04 - tf.__operators__.getitem_3_loss: 2.2923e-04 - tf.__operators__.getitem_4_loss: 2.8364e-04 - tf.__operators__.getitem_5_loss: 2.3078e-04 - val_loss: 0.0016 - val_tf.__operators__.getitem_3_loss: 0.0017 - val_tf.__operators__.getitem_4_loss: 0.0015 - val_tf.__operators__.getitem_5_loss: 0.0017\n",
      "Epoch 5/5\n",
      "6370/6370 [==============================] - 232s 36ms/step - loss: 2.3511e-04 - tf.__operators__.getitem_3_loss: 2.1974e-04 - tf.__operators__.getitem_4_loss: 2.4996e-04 - tf.__operators__.getitem_5_loss: 2.2078e-04 - val_loss: 0.0017 - val_tf.__operators__.getitem_3_loss: 0.0022 - val_tf.__operators__.getitem_4_loss: 0.0014 - val_tf.__operators__.getitem_5_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "from orion import Orion\n",
    "\n",
    "hyperparameters = {\n",
    "    \"mlstars.custom.timeseries_preprocessing.time_segments_aggregate#1\": {\n",
    "        'interval': 1\n",
    "    },\n",
    "    \"mlstars.custom.timeseries_preprocessing.rolling_window_sequences#1\": {\n",
    "        'target_column': 0\n",
    "    },\n",
    "    'orion.primitives.aer.AER#1': {\n",
    "        'epochs': 5,\n",
    "        'verbose': True\n",
    "    }\n",
    "}\n",
    "\n",
    "orion = Orion(\n",
    "    pipeline='aer',\n",
    "    hyperparameters=hyperparameters\n",
    ")\n",
    "\n",
    "orion.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be a ``pandas.DataFrame`` containing a table with the detected anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15923/15923 [==============================] - 43s 3ms/step\n",
      "15923/15923 [==============================] - 64s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1704459904</td>\n",
       "      <td>1704460350</td>\n",
       "      <td>0.342368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1704460750</td>\n",
       "      <td>1704461240</td>\n",
       "      <td>0.787530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1704473451</td>\n",
       "      <td>1704474093</td>\n",
       "      <td>0.722064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start         end  severity\n",
       "0  1704459904  1704460350  0.342368\n",
       "1  1704460750  1704461240  0.787530\n",
       "2  1704473451  1704474093  0.722064"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orion.detect(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "orion.save(\"/Users/coloner/IdeaProjects/ml/Orion/data/model.picle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/Users/coloner/IdeaProjects/ml/Orion/data/labelsTimeSeries.csv\")\n",
    "\n",
    "labels['timestamp'] = pd.to_datetime(labels.index, unit='s', origin=reference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start         end\n",
      "0    1704077902  1704077902\n",
      "1    1704078624  1704078624\n",
      "2    1704079085  1704079085\n",
      "3    1704079520  1704079520\n",
      "4    1704079903  1704079903\n",
      "..          ...         ...\n",
      "438  1704575911  1704575911\n",
      "439  1704576012  1704576012\n",
      "440  1704576250  1704576250\n",
      "441  1704576580  1704576580\n",
      "442  1704576695  1704576695\n",
      "\n",
      "[443 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start         end\n",
      "0    1704576831  1704077902\n",
      "1    1704576831  1704078624\n",
      "2    1704576831  1704079085\n",
      "3    1704576831  1704079520\n",
      "4    1704576831  1704079903\n",
      "..          ...         ...\n",
      "438  1704576831  1704575911\n",
      "439  1704576831  1704576012\n",
      "440  1704576831  1704576250\n",
      "441  1704576831  1704576580\n",
      "442  1704576831  1704576695\n",
      "\n",
      "[443 rows x 2 columns]\n",
      "CPU times: user 6.61 s, sys: 18.3 ms, total: 6.62 s\n",
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "current_start = None\n",
    "result = []\n",
    "for i in range(len(labels)):\n",
    "    if current_start != None and labels.iloc[i]['label'] == 0:\n",
    "        result.append({\"start\": current_start, \"end\" : labels.iloc[i-1][\"timestamp\"]})\n",
    "        current_start = None\n",
    "    elif current_start == None and labels.iloc[i]['label'] == 1:\n",
    "        current_start = row['timestamp']\n",
    "if current_start != None:\n",
    "    result.append({\"start\": current_start, \"end\" : labels.iloc[-1][\"timestamp\"]})\n",
    "\n",
    "df_range = pd.DataFrame(result)\n",
    "print(df_range)\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start         end\n",
      "0    1704077902  1704077902\n",
      "1    1704078624  1704078624\n",
      "2    1704079085  1704079085\n",
      "3    1704079520  1704079520\n",
      "4    1704079903  1704079903\n",
      "..          ...         ...\n",
      "438  1704575911  1704575911\n",
      "439  1704576012  1704576012\n",
      "440  1704576250  1704576250\n",
      "441  1704576580  1704576580\n",
      "442  1704576695  1704576695\n",
      "\n",
      "[443 rows x 2 columns]\n",
      "CPU times: user 8.99 ms, sys: 3.12 ms, total: 12.1 ms\n",
      "Wall time: 9.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where label is 1\n",
    "df_filtered = labels[labels['label'] == 1]\n",
    "\n",
    "# Identify consecutive groups\n",
    "df_filtered['group'] = (df_filtered['timestamp'].diff() != 1).cumsum()\n",
    "\n",
    "# Aggregate start and end of each group\n",
    "df_range2 = df_filtered.groupby('group').agg(start=('timestamp', 'first'), end=('timestamp', 'last')).reset_index(drop=True)\n",
    "\n",
    "print(df_range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10702     True\n",
       "11424     True\n",
       "11885     True\n",
       "12320     True\n",
       "12703     True\n",
       "          ... \n",
       "508711    True\n",
       "508812    True\n",
       "509050    True\n",
       "509380    True\n",
       "509495    True\n",
       "Name: timestamp, Length: 443, dtype: bool"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['timestamp'].diff() != 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['timestamp'] = labels['timestamp'].view('int64') \n",
    "labels['timestamp'] /= 1000000000\n",
    "labels['timestamp'] = labels['timestamp'].astype('int64')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
